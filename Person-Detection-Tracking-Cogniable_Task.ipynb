{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T18:39:18.905890Z",
     "iopub.status.busy": "2024-09-01T18:39:18.904958Z",
     "iopub.status.idle": "2024-09-01T18:42:46.417099Z",
     "shell.execute_reply": "2024-09-01T18:42:46.416106Z"
    },
    "papermill": {
     "duration": 207.52187,
     "end_time": "2024-09-01T18:42:46.419584",
     "exception": false,
     "start_time": "2024-09-01T18:39:18.897714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install YOLOv5 and dependencies\n",
    "!pip install git+https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "!pip install -r requirements.txt\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e768a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ensure the path of yolo and where it loaded and for the output file too\n",
    "model = torch.hub.load('/kaggle/working/yolov5', 'yolov5s', source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30621ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/kaggle/input/correct-dataset-cogniable/'\n",
    "output_dir = '/kaggle/working/output_videos'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "tracker = DeepSort(max_age=30, n_init=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e3957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T18:42:47.734375Z",
     "iopub.status.busy": "2024-09-01T18:42:47.733414Z",
     "iopub.status.idle": "2024-09-01T18:42:56.982833Z",
     "shell.execute_reply": "2024-09-01T18:42:56.982005Z"
    },
    "papermill": {
     "duration": 9.332915,
     "end_time": "2024-09-01T18:42:56.985263",
     "exception": false,
     "start_time": "2024-09-01T18:42:47.652348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_human_like(bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    aspect_ratio = height / width\n",
    "    return 1.5 <= aspect_ratio <= 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0810a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_detection(frame):\n",
    "    \"\"\"Detects persons in a frame using YOLOv5 and filters out non-human detections.\"\"\"\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "    for det in results.xyxy[0].cpu().numpy():\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = det\n",
    "        if class_id == 0 and is_human_like([x_min, y_min, x_max, y_max]):  # Ensure detection is a human-like shape\n",
    "            detections.append([x_min, y_min, x_max, y_max, confidence])\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1af151e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T18:42:57.150597Z",
     "iopub.status.busy": "2024-09-01T18:42:57.149498Z",
     "iopub.status.idle": "2024-09-01T18:42:57.168131Z",
     "shell.execute_reply": "2024-09-01T18:42:57.167267Z"
    },
    "papermill": {
     "duration": 0.103069,
     "end_time": "2024-09-01T18:42:57.169972",
     "exception": false,
     "start_time": "2024-09-01T18:42:57.066903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is main process video where detection, tracking and writing of video is done for each frames is done\n",
    "def process_video(video_file):\n",
    "    video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "    video_output_dir = os.path.join(output_dir, video_name)\n",
    "    os.makedirs(video_output_dir, exist_ok=True)\n",
    "    \n",
    "    persons_folder = os.path.join(video_output_dir, 'persons')\n",
    "    os.makedirs(persons_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Setup video capture and writer to write the output of the code\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Error opening video file: {video_file}\")\n",
    "        output_video_path = os.path.join(video_output_dir, f'{video_name}_output.mp4')\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "        captured_images = {}\n",
    "        person_id_counter = 1\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            detections = perform_detection(frame)\n",
    "            formatted_detections = []\n",
    "            for det in detections:\n",
    "                x_min, y_min, x_max, y_max, confidence = det\n",
    "                formatted_detections.append(([x_min, y_min, x_max, y_max], confidence))\n",
    "\n",
    "            tracked_objects = tracker.update_tracks(formatted_detections, frame=frame)\n",
    "\n",
    "            for track in tracked_objects:\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "\n",
    "                track_id = track.track_id\n",
    "                bbox = track.to_tlbr()  # Get bounding box in [x_min, y_min, x_max, y_max] format\n",
    "                cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"ID: {track_id}\", (int(bbox[0]), int(bbox[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                if track_id not in captured_images:\n",
    "                    person_image = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "                    if person_image.size > 0:\n",
    "                        person_folder = os.path.join(persons_folder, f'person{person_id_counter}')\n",
    "                        os.makedirs(person_folder, exist_ok=True)\n",
    "                        person_image_path = os.path.join(person_folder, f'person_{track_id}.jpg')\n",
    "                        cv2.imwrite(person_image_path, person_image)\n",
    "\n",
    "                        captured_images[track_id] = person_image_path\n",
    "                        person_id_counter += 1\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {video_file}: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        out.release()\n",
    "    # Display the video\n",
    "    ipd.display(ipd.Video(output_video_path, width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bce4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T18:42:57.332677Z",
     "iopub.status.busy": "2024-09-01T18:42:57.331784Z",
     "iopub.status.idle": "2024-09-01T22:07:09.503351Z",
     "shell.execute_reply": "2024-09-01T22:07:09.502324Z"
    },
    "papermill": {
     "duration": 12252.255892,
     "end_time": "2024-09-01T22:07:09.505937",
     "exception": false,
     "start_time": "2024-09-01T18:42:57.250045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_files = [os.path.join(video_path, f) for f in os.listdir(video_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "for i, video_file in enumerate(video_files):\n",
    "    try:\n",
    "        print(f\"Working on Video named {i+1}: {video_file}\")\n",
    "        process_video(video_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {video_file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5619052,
     "sourceId": 9283055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5628438,
     "sourceId": 9296309,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12477.241515,
   "end_time": "2024-09-01T22:07:13.353735",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-01T18:39:16.112220",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
